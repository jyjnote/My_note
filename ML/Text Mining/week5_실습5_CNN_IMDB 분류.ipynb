{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd411cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#최대 10,000개의 단어만을 허용하여 데이터를 받아옵니다.\n",
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words = vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a7fdc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#X_train을 상위 5개만 출력해봅시다.\n",
    "#print(X_train[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d9ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 크기(shape) : (25000, 200)\n",
      "X_test의 크기(shape) : (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "max_len = 200\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)\n",
    "\n",
    "\n",
    "# 패딩이 되었는지 크기(shape)를 확인해봅시다.\n",
    "print('X_train의 크기(shape) :',X_train.shape)\n",
    "print('X_test의 크기(shape) :',X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf48981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a239656",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "dropout_ratio = 0.3\n",
    "num_filters = 256\n",
    "kernel_size = 3\n",
    "hidden_units = 128\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0b8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3951 - acc: 0.8100\n",
      "Epoch 1: val_acc improved from -inf to 0.88384, saving model to best_model.h5\n",
      "782/782 [==============================] - 69s 87ms/step - loss: 0.3951 - acc: 0.8100 - val_loss: 0.2729 - val_acc: 0.8838\n",
      "Epoch 2/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9195\n",
      "Epoch 2: val_acc improved from 0.88384 to 0.88404, saving model to best_model.h5\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 0.2098 - acc: 0.9195 - val_loss: 0.2772 - val_acc: 0.8840\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9648\n",
      "Epoch 3: val_acc improved from 0.88404 to 0.88692, saving model to best_model.h5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.1011 - acc: 0.9648 - val_loss: 0.3140 - val_acc: 0.8869\n",
      "Epoch 4/20\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9848\n",
      "Epoch 4: val_acc did not improve from 0.88692\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 0.0450 - acc: 0.9848 - val_loss: 0.3871 - val_acc: 0.8801\n",
      "Epoch 4: early stopping\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3140 - acc: 0.8869\n",
      "\n",
      " 테스트 정확도: 0.8869\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor = 'val_acc', mode = 'max', verbose = 1, save_best_only = True)\n",
    "\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_test, y_test), callbacks=[es, mc])\n",
    "\n",
    "#저장된 모델을 로드하여 테스트 정확도를 확인합니다.\n",
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d8492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
