{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d34e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#영화 사이트 IMDB의 리뷰 데이터입니다. \n",
    "#이 데이터는 리뷰에 대한 텍스트와 해당 리뷰가 긍정인 경우 1을 부정인 경우 0으로 표시한 레이블로 구성된 데이터입니다.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786b072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화 리뷰 데이터를 갖고오겠습니다. \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1266241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717])\n",
      " list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077])\n",
      " list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975])\n",
      " ...\n",
      " list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518])\n",
      " list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470])\n",
      " list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a6ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 25000\n",
      "테스트용  개수 : 25000\n",
      "{0, 1}\n",
      "카테고리 : 2\n"
     ]
    }
   ],
   "source": [
    "# 데이터 섹 길이 및 카테고리 확인 \n",
    "\n",
    "print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
    "print('테스트용  개수 : {}'.format(len(X_test)))\n",
    "\n",
    "num_class = len(set(y_train))\n",
    "\n",
    "print('카테고리 : {}'.format(num_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8f08d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 배열 프린트\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5d92886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2494\n",
      "리뷰의 평균 길이 : 238.71364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  25,000개의 훈련용 리뷰의 각 길이는 전부 다른데, \n",
    "#    리뷰의 길이 분포를 그래프로 시각화해보겠습니다.\n",
    "\n",
    "len_result = [len(s) for s in X_train]\n",
    "\n",
    "print('리뷰의 최대 길이 : {}'.format(np.max(len_result)))\n",
    "print('리뷰의 평균 길이 : {}'.format(np.mean(len_result)))\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(len_result,bins=300)\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66dbcc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 레이블에 대한 빈도수 : \n",
      "[[    0     1]\n",
      " [12500 12500]]\n"
     ]
    }
   ],
   "source": [
    "# 긍정/부정 분포 즉 0과1의 분포 확인 \n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print('각 레이블에 대한 빈도수 : ')\n",
    "\n",
    "print(np.asarray((unique_elements,counts_elements)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4379f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 숫자와 단어 매핑 \n",
    "\n",
    "word_to_index = imdb.get_word_index()\n",
    "\n",
    "index_to_word = {}\n",
    "for key,value in word_to_index.items():\n",
    "    index_to_word[value+3] = key\n",
    "    \n",
    "# 첫번째 리뷰 단어 매핑\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index] = token\n",
    "\n",
    "# <pad>: padding, 길이를 맞출때 사용하는 비어있는(사용x) 토큰\n",
    "# <sos>: start of sentence, 문장의 시작을 알리는 토큰\n",
    "# <unk>: unknown, 모델이 인식할 수 없는 토큰\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16cf85e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([index_to_word[index] for index in X_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f898fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 만들기 \n",
    "#우선 필요한 패키지를 가져옵니다.\n",
    "\n",
    "import re\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bea94da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee01793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩하기\n",
    "# pad_sequences() 활용. 길이는 max_len에 넣는 값으로 정해집니다. 훈련 데이터가 정한 길이를 초과하면 초과분을 삭제하고, 부족하면 0으로 채웁니다.\n",
    "# 패딩은 컨볼루션 연산을 수행하기 전에 입력 이미지의 크기를 조정하는 방법\n",
    "# 패딩을 하면 이미지의 크기가 커지므로, 필터가 이미지를 모두 커버할 수 있고 특징을 더 잘 추출할 수 있습니다\n",
    "\n",
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b28ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding()은 두 개의 인자를 받는데, 첫번째 인자는 단어 집합의 크기이며 \n",
    "# 두번째 인자는 임베딩 후의 벡터 크기입니다. 여기서는 100을 선택했습니다. \n",
    "# 즉, 입력 데이터에서 모든 단어는 100차원의 임베딩 벡터로 표현됩니다.\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(GRU(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b6aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 얼리스톱과 체크 포인터 설정\n",
    "# 검증 데이터의 손실(loss)이 증가하면, 과적합 징후이므로 검증 데이터 손실이 4회 증가하면 \n",
    "# 학습을 중단하는 조기 종료(EarlyStopping)를 사용합니다. \n",
    "# 또한, ModelCheckpoint를 사용하여 검증 데이터의 정확도가 이전보다 좋아질 경우에만 모델을 저장하도록 합니다.\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a904ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.5688 - acc: 0.7004\n",
      "Epoch 1: val_acc improved from -inf to 0.76940, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 459s 1s/step - loss: 0.5688 - acc: 0.7004 - val_loss: 0.4840 - val_acc: 0.7694\n",
      "Epoch 2/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.4230 - acc: 0.8119\n",
      "Epoch 2: val_acc improved from 0.76940 to 0.78960, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 488s 1s/step - loss: 0.4230 - acc: 0.8119 - val_loss: 0.4489 - val_acc: 0.7896\n",
      "Epoch 3/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3832 - acc: 0.8379\n",
      "Epoch 3: val_acc improved from 0.78960 to 0.84920, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 473s 1s/step - loss: 0.3832 - acc: 0.8379 - val_loss: 0.3557 - val_acc: 0.8492\n",
      "Epoch 4/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3488 - acc: 0.8540\n",
      "Epoch 4: val_acc did not improve from 0.84920\n",
      "334/334 [==============================] - 489s 1s/step - loss: 0.3488 - acc: 0.8540 - val_loss: 0.3927 - val_acc: 0.8486\n",
      "Epoch 5/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3216 - acc: 0.8679\n",
      "Epoch 5: val_acc did not improve from 0.84920\n",
      "334/334 [==============================] - 485s 1s/step - loss: 0.3216 - acc: 0.8679 - val_loss: 0.3983 - val_acc: 0.8342\n",
      "Epoch 6/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2960 - acc: 0.8800\n",
      "Epoch 6: val_acc improved from 0.84920 to 0.85120, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 478s 1s/step - loss: 0.2960 - acc: 0.8800 - val_loss: 0.3360 - val_acc: 0.8512\n",
      "Epoch 7/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2755 - acc: 0.8890\n",
      "Epoch 7: val_acc did not improve from 0.85120\n",
      "334/334 [==============================] - 470s 1s/step - loss: 0.2755 - acc: 0.8890 - val_loss: 0.3839 - val_acc: 0.8368\n",
      "Epoch 8/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2617 - acc: 0.8954\n",
      "Epoch 8: val_acc improved from 0.85120 to 0.86440, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 479s 1s/step - loss: 0.2617 - acc: 0.8954 - val_loss: 0.3180 - val_acc: 0.8644\n",
      "Epoch 9/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2491 - acc: 0.9013\n",
      "Epoch 9: val_acc did not improve from 0.86440\n",
      "334/334 [==============================] - 488s 1s/step - loss: 0.2491 - acc: 0.9013 - val_loss: 0.3524 - val_acc: 0.8430\n",
      "Epoch 10/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2385 - acc: 0.9065\n",
      "Epoch 10: val_acc improved from 0.86440 to 0.86960, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 486s 1s/step - loss: 0.2385 - acc: 0.9065 - val_loss: 0.3121 - val_acc: 0.8696\n",
      "Epoch 11/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2272 - acc: 0.9125\n",
      "Epoch 11: val_acc did not improve from 0.86960\n",
      "334/334 [==============================] - 485s 1s/step - loss: 0.2272 - acc: 0.9125 - val_loss: 0.3589 - val_acc: 0.8526\n",
      "Epoch 12/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2175 - acc: 0.9162\n",
      "Epoch 12: val_acc improved from 0.86960 to 0.87220, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 493s 1s/step - loss: 0.2175 - acc: 0.9162 - val_loss: 0.3000 - val_acc: 0.8722\n",
      "Epoch 13/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.9208\n",
      "Epoch 13: val_acc improved from 0.87220 to 0.87780, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 496s 1s/step - loss: 0.2082 - acc: 0.9208 - val_loss: 0.3334 - val_acc: 0.8778\n",
      "Epoch 14/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1978 - acc: 0.9244\n",
      "Epoch 14: val_acc did not improve from 0.87780\n",
      "334/334 [==============================] - 495s 1s/step - loss: 0.1978 - acc: 0.9244 - val_loss: 0.3423 - val_acc: 0.8642\n",
      "Epoch 15/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1886 - acc: 0.9286\n",
      "Epoch 15: val_acc did not improve from 0.87780\n",
      "334/334 [==============================] - 496s 1s/step - loss: 0.1886 - acc: 0.9286 - val_loss: 0.4187 - val_acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 로스펑션 설정\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)\n",
    "\n",
    "# 긍정인지 부정인지에 대한 이진 판별값이 출력이 되기 때문에, 손실 함수는 binary_crossentropy를 사용합니다. \n",
    "# 최적화 함수는 rmsprop를 사용하였습니다. 또한, 에포크마다 정확도를 구하기위해 accuracy를 추가해줍니다.\n",
    "# 에포크는 총 10회를 수행하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18163e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 43s 54ms/step - loss: 0.3355 - acc: 0.8751\n",
      "\n",
      " 테스트 정확도: 0.8751\n"
     ]
    }
   ],
   "source": [
    "# 조기종료 모델 불러 오기\n",
    "# . 훈련이 다 되었다면 이제 테스트 데이터에 대해서 정확도를 평가할 차례입니다. \n",
    "#   훈련 과정에서 검증 데이터의 정확도가 가장 높았을 때 저장된 모델인 'GRU_model.h5'를 로드합니다.\n",
    "\n",
    "loaded_model = load_model('GRU_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bd493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
